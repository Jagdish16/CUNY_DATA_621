---
title: "DS621_Group2_HW3_JC"
author: "Jagdish Chhabria"
date: "4/17/2021"
output: html_document
---

**Group 2 members:** _Diego Correa, Jagdish Chhabria, Orli Khaimova, Richard Zheng, Stephen Haslett_.

## Introduction

### Assignment Objective

In this homework assignment, you will explore, analyze and model a data set containing information on crime for various neighborhoods of a major city. Each record has a response variable indicating whether or not the crime rate is above the median crime rate (1) or not (0). Your objective is to build a binary logistic regression model on the training data set to predict whether the neighborhood will be at risk for high crime levels. You will provide classifications and probabilities for the evaluation data set using your binary logistic regression model. You can only use the variables given to you (or variables that you derive from the variables provided).

#### Data

There are 2 datasets provided - The crime training dataset and the crime evaluation dataset. The training dataset contains 13 columns and 466 rows. Each record in the Boston crime training dataset represents a neighborhood. For this assignment, the target variable in the dataset is the "target" which is a binary variable. Since there is no separate column representing the neighborhood identifer, we use the dataframe index as the unique identifier or primary key for this data.

A short description of the variables of interest in the data set is given below:

| Variable Name | Definition                                                           | Variable Type |
|---------------|----------------------------------------------------------------------|---------------|
| zn       | proportion of residential land zoned for large lots (over 25000 square feet) | predictor |
| indus    | proportion of non-retail business acres per suburb                           | predictor |
| chas     | a dummy var. for whether the suburb borders the Charles River (1) or not (0) | predictor |
| nox      | nitrogen oxides concentration (parts per 10 million)                         | predictor |
| rm       | average number of rooms per dwelling                                         | predictor |
| age      | proportion of owner-occupied units built prior to 1940                       | predictor |
| dis      | weighted mean of distances to five Boston employment centers                 | predictor |
| rad      | index of accessibility to radial highways                                    | predictor |
| tax      | full-value property-tax rate per $10,000                                     | predictor |
| ptratio  | pupil-teacher ratio by town                                                  | predictor |
| black    | 1000(Bk - 0.63)2 where Bk is the proportion of blacks by town                | predictor |
| lstat    | lower status of the population (percent)                                     | predictor |
| medv     | median value of owner-occupied homes in $1000s                               | predictor |
| target   | whether the crime rate is above the median crime rate (1) or not (0)         | response  |

### Purpose of Analysis

The purpose of the analysis is to find which of the predictors have significant ability to explain the variation in the response variable (whether or not the crime rate is above the median crime rate (1) or not (0)), and to make a prediction for all the records provided in the test data set, based on the predicted probabilities and a threshold of 0.5.

### Method

The method used is a logistic regression model on the training data to predict the probability of the crime rate for each neighborhood being above or below the median crime rate. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE, fig.pos="!h") #sets global options for chunks when *knit*
knitr::include_graphics
#Note: messages and warnings will still show when running in the R console

# Disable scientific numbers for readability purposes.
options(scipen = 999)

library(dplyr)
library(gridExtra)
library(DT)
library(MASS)
library(tidyverse) #includes dplyr and ggplot2
library(reshape2)
library(kableExtra)
library(corrplot)
library(Hmisc)
library(PerformanceAnalytics)
library(car)
library(caret)
library(MLmetrics)

```


```{r setup, include=FALSE}
# Load in the training data.
url = "https://raw.githubusercontent.com/Jagdish16/CUNY_DATA_621/main/homework 3/crime-training-data_modified.csv"
#training_set <- read.csv(url)
training_set<-read.csv(url)%>%dplyr::select(target,everything())
prediction_set<-training_set

```

```{r}
#rm(training_set)
```


```{r}
# Take a look at the training dataset
glimpse(training_set)
```

```{r}
# Check for missing values
any(is.na.data.frame(training_set))
```
```{r}

```


```{r}
# Converting the 2 categorical columns to factors
training_set_mod<-training_set%>%mutate(chas = as.factor(chas),target = as.factor(target))%>% dplyr::select(target, everything())
#DT::datatable(training_set)

```


```{r }
# Explore the various columns of the training dataset
summary(training_set)

```

```{r}
# Check the class imbalance for the target variable
tgt_variable<-table(training_set$target)
tgt_variable
```

```{r}
# Check the distributions of the various columns
#hist.data.frame(training_set)

```


```{r}
# Check the distributions of the numeric columns
train_num<-select_if(training_set,is.numeric)
train_num %>%keep(is.numeric) %>%gather() %>%ggplot(aes(value))+facet_wrap(~ key, scales = "free") +   geom_density()

```

```{r }
# Plot box plots for the different predictors for each value of the target variable
par(mfrow = c(4,3))
boxplot(zn~target, ylab="zn", xlab= "target", col="steel blue",data = training_set)
boxplot(indus~target, ylab="indus", xlab= "target", col="steel blue",data =  training_set)
boxplot(chas~target, ylab="chas", xlab= "target", col="steel blue",data =  training_set)
boxplot(nox~target, ylab="nox", xlab= "target", col="steel blue",data =  training_set)
boxplot(rm~target, ylab="rm", xlab= "target", col="steel blue",data =  training_set)
boxplot(age~target, ylab="age", xlab= "target", col="steel blue",data =  training_set)
boxplot(dis~target, ylab="dis", xlab= "target", col="steel blue",data =  training_set)
boxplot(rad~target, ylab="rad", xlab= "target", col="steel blue",data =  training_set)
boxplot(tax~target, ylab="tax", xlab= "target", col="steel blue",data =  training_set)
boxplot(ptratio~target, ylab="ptratio", xlab= "target", col="steel blue",data =  training_set)
boxplot(lstat~target, ylab="lstat", xlab= "target", col="steel blue",data =  training_set)
boxplot(medv~target, ylab="medv", xlab= "target", col="steel blue",data =  training_set)
```

```{r, echo=FALSE}
# Plot correlations between the variables

#training_set %>%  cor() %>% corrplot.mixed(upper = 'pie', lower = 'number', order = 'hclust', tl.col = "black")
corrplot(cor(training_set), method="square")

```


```{r}
# Derive correlations between the variables
#PerformanceAnalytics::chart.Correlation(training_set, histogram=TRUE, pch=19)

training_set%>%cor() %>%as.data.frame()%>%rownames_to_column('Variable')%>%
dplyr::rename(Correlation_vs_Response_Variable = target)

```


```{r}
# Fit a logistic regression model to the full dataset as-is
model1<-glm(target~.,family = binomial, data = training_set)
summary(model1)
```

```{r}
# Apply step-wise AIC on the model above to identify key features
model2 <- stepAIC(model1, trace = FALSE)
summary(model2)
```
```{r}
#BIC

```


```{r}
#vif(model1)

```

```{r}
# Using model 2, predict the probability of crime in the neighborhoods and then use those probabilities to classify the neighborhoods into a binary classification based on a threshold probability of 0.5

probabilities<-predict(model2,training_set,type = "response")
predict.class<-ifelse(probabilities > 0.5, 1, 0)
prediction_set$jagdish.prediction<-predict.class
table("Predictions" = prediction_set$jagdish.prediction, "Actual" = training_set$target)
```


```{r}
glimpse(prediction_set)
```


```{r}
# Function for accuracy of predictions
accuracy <- function(dataf){
  metrics <- table("Predictions" = dataf$jagdish.prediction, "Actual" = dataf$target)
  
  TP <- metrics[2,2]
  TN <- metrics[1,1]
  FP <- metrics[2,1]
  FN <- metrics[1,2]
  
  return((TP + TN)/(TP + FP + TN + FN))
}

```


```{r}
# Function for classification error of predictions
classification.error<- function(dataf){
  metrics <- table("Predictions" = dataf$jagdish.prediction, "Actual" = dataf$target)
  
  TP <- metrics[2,2]
  TN <- metrics[1,1]
  FP <- metrics[2,1]
  FN <- metrics[1,2]
  
  return((FP + FN)/(TP + FP + TN + FN))
}
```


```{r}
# Function for precision of predictions
precision <- function(dataf){
  metrics <- table("Predictions" = dataf$jagdish.prediction, "Actual" = dataf$target)
  
  TP <- metrics[2,2]
  TN <- metrics[1,1]
  FP <- metrics[2,1]
  FN <- metrics[1,2]
  
  return(TP/(TP + FP))
}

```


```{r}
# Function for sensitivity of predictions
sensitivity <- function(dataf){
  metrics <- table("Predictions" = dataf$jagdish.prediction, "Actual" = dataf$target)
  
  TP <- metrics[2,2]
  TN <- metrics[1,1]
  FP <- metrics[2,1]
  FN <- metrics[1,2]
  
  return((TP)/(TP + FN))
}

```


```{r}
# Function for specificity of predictions
specificity<- function(dataf){
  metrics <- table("Predictions" = dataf$jagdish.prediction, "Actual" = dataf$target)
   
  TP <- metrics[2,2]
  TN <- metrics[1,1]
  FP <- metrics[2,1]
  FN <- metrics[1,2]
  
  return((TN)/(TN + FP))
}
```


```{r}
# Function for F1 Score of predictions
f1score <- function(dataf){
  metrics <- table("Predictions" = dataf$jagdish.prediction, "Actual" = dataf$target)
   
  TP <- metrics[2,2]
  TN <- metrics[1,1]
  FP <- metrics[2,1]
  FN <- metrics[1,2]
  
  f1score <- (2 * precision(dataf) * sensitivity(dataf)) / (precision(dataf) + sensitivity(dataf))
  return(f1score)
}
```


```{r }
# Calculate and display the classification metrics
metric.names <- c('Accuracy','Classification Error Rate', 'Precision', 'Sensitivity','Specificity', 'F1 Score')
scores<-round(c(accuracy(prediction_set), classification.error(prediction_set), precision(prediction_set), sensitivity(prediction_set), specificity(prediction_set), f1score(prediction_set)),4)

df_metrics <- as.data.frame(cbind(metric.names, scores))
kable(df_metrics)
```


```{r}
# Derive the confusion matrix
confusionMatrix(data=factor(prediction_set$target), factor(prediction_set$jagdish.prediction), positive = "1")

```


```{r}
#predict_set<-prediction_set%>%subset(prediction_set$target, prediction_set$jagdish.prediction)
#prSummary(predict_set)
```


```{r}

```

```{r}

```


```{r}

```




---
title: "Moneyball: DATA621 Project #1"
author: "Team 2"
date: "03/07/2021"
output: 
  pdf_document:
    toc: true
    number_sections: true
    highlight: tango
    df_print: kable
fontsize: 11pt
geometry: margin=1in
---

Alice is currently working in this file.

## Introduction

* Data
* Purpose of Analysis
* Method?

## Setup

This analysis requires installation of `tidyverse`,`corrplot`, and `reshape2`.

```{r, setup, include=FALSE}
knitr::opts_chunk$set(fig.width = 8, message=FALSE, warning=FALSE, cache = TRUE)
#This will not appear in the PDF. This hides all the warnings and messages, and caches the results of heavy chunks so it loads faster.
```

```{r pckgs, include=FALSE}
library(tidyverse)
library(reshape2)
library(corrplot)
```

### Load Raw Data

The data has been divided in advance into a training set, `training_raw`, and an evaluation set, `eval_raw`.  The evaluation set does *not* containt the target information, so in order to evaluate the strength of our model, we will subdivide the training into a training set and a test set. 

```{r load_data}
url1 = "https://raw.githubusercontent.com/Jagdish16/CUNY_DATA_621/main/project_1/moneyball-training-data.csv"
training_raw = read_csv(url1)

url2 = "https://raw.githubusercontent.com/Jagdish16/CUNY_DATA_621/main/project_1/moneyball-evaluation-data.csv"
eval_raw=read_csv(url2)

head(training_raw)
```

### Rename Columns

Next, we will rename the columns to be more human-readable.

```{r rename}

training_names <- training_raw %>%
  select(-INDEX) %>%
  rename_with(~ gsub("TEAM_", "", .x)) %>%
  rename_with(stringr::str_to_title) %>%
  dplyr::rename(
    Wins = Target_wins,
    Hits = Batting_h,
    Doubles = Batting_2b,
    Triples = Batting_3b,
    HomeRuns = Batting_hr,
    Walks_AtBat = Batting_bb,
    StrikeOuts_AtBat = Batting_so,
    BasesStolen = Baserun_sb,
    OutStealingBases = Baserun_cs,
    Hits_Allowed = Pitching_h,
    HitByPitch_AtBat = Batting_hbp,
    Errors = Fielding_e,
    HomeRuns_Allowed = Pitching_hr,
    Walks_Allowed = Pitching_bb,
    StrikeOuts = Pitching_so,
    DoublePlays = Fielding_dp
  )
```

### Split into Test-Train Sets

Using `dplyr::sample_frac` function, we can split the  data into 80% training, 20% test data. 

```{r test-train-split}
set.seed(234)
training <- sample_frac(training_names, 0.8)
sample_id <- as.numeric(rownames(training))
test <- training_names[-sample_id,]
```

## Data Exploration

What does the data look like? Using `ggplot::facet_wrap`, we can see many box plots at once.

``` {r boxplots, warning=FALSE}
long <- training %>% as.data.frame() %>% melt

long %>%
  ggplot(aes(x=value)) + 
  geom_boxplot() + 
  facet_wrap(~variable, scales='free')
  
```

We can also see that soe variables are missing many cases. Given that getting hit by a pitch is fairly rare, it may be best to assume that these missing cases are 0, rather than omit that many cases. Alternatively we can drop that variable entirely. 

```{r missing}
missing <- sapply(training, FUN = function(x) sum(is.na(x)))
missing
```

```{r}
test_missing <- function(){
  missingALot <- c("HitByPitch_AtBat", "OutStealingBases", "DoublePlays")
  for (feature in missingALot){
    print(feature)
    df <- training[, c("Wins", feature)] %>% na.omit()
    model <- lm(df$Wins ~ as.vector(df[,feature]))
  }  
}

test_missing()

model <- lm(Wins ~ HitByPitch_AtBat, training)
plot(Wins ~ HitByPitch_AtBat, training) +
abline(model, color="red")
```

### Feature Correlation

```{r}
# computing correlation matrix
corr <- round(cor(training), digits = 1)

corrplot(corr, type = 'upper', addCoef.col = 'black', tl.col = 'black', tl.srt = 45)
```

## Feature Selection
We should drop highly correlated values, but which ones to drop?

Using our understanding of baseball, we can also tell which features are highly correlated because they are in fact calculated from a common statistic (e.g. Runs Hit, and Double Hit both include how many doubles were hit!) versus variables which are correlated in fact but not in function (e.g. Runs Allowed Pitcher vs Runs Allowed Field -- this is a measure of the pitching staff versus the batting so while these tend to be similar they are in fact measuring the skill of different players at different points in the game.)

Oddly, although pitching hits and pitching homeruns are likewise connecting in the real world, they are negatively correlated at just the 0.1 value in the data.

Because Team Batting Hits includes the data from singles, double, triples and home runs, it might sense to drop Team Batting Hits and add a new variable -- Team Batting Singles

```{r}

```






```{r eval=FALSE}
#re-factoring

FancyHist <- function(field, title){
  ggplot(data = moneyball_training, aes(x = get(field)))  +
    geom_histogram( color = 'black', fill =  'gray') + 
    geom_vline(aes(xintercept = mean(get(field))),
               linetype = 'dashed', size = 2, color = 'blue') +
    #geom_label(aes(x = 50, y = 125, 
    #               label = str_replace_all(toString(summary(moneyball_training['WINS'])), ',', '\n')
    #               )) +
    labs(title = title, y = 'Count', x=field)
}

FancyHist('WINS', "Wins")

#Hits
ggplot(data = moneyball_training, aes(x = B_H))  +
  geom_histogram( color = 'black', fill =  'gray') + 
  geom_vline(aes(xintercept = mean(B_H)),
             linetype = 'dashed', size = 2, color = 'blue') +
  geom_label(aes(x = 1250, y = 100, 
                 label = str_replace_all(toString(summary(moneyball_training['B_H'])), ',', '\n')
                 )) +
  labs(title = 'Base Hits Histogram Plot', y = 'Count', x = 'Base Hits')

# Doubles
ggplot(data = moneyball_training, aes(x = B_2B))  +
  geom_histogram( color = 'black', fill =  'gray') + 
  geom_vline(aes(xintercept = mean(B_2B)),
             linetype = 'dashed', size = 2, color = 'blue') +
  geom_label(aes(x = 160, y = 100, 
                 label = str_replace_all(toString(summary(moneyball_training['B_2B'])), ',', '\n')
                 )) +
  labs(title = 'Doubles Histogram Plot', y = 'Count', x = 'Doubles')


# Triples
ggplot(data = moneyball_training, aes(x = B_3B))  +
  geom_histogram( color = 'black', fill =  'gray') + 
  geom_vline(aes(xintercept = mean(B_3B)),
             linetype = 'dashed', size = 2, color = 'blue') +
  geom_label(aes(x = 75, y = 130, 
                 label = str_replace_all(toString(summary(moneyball_training['B_3B'])), ',', '\n')
                 )) +
  labs(title = 'Triples Histogram Plot', y = 'Count', x = 'Triples')


# Homeruns
ggplot(data = moneyball_training, aes(x = B_HR))  +
  geom_histogram( color = 'black', fill =  'gray') + 
  geom_vline(aes(xintercept = mean(B_HR)),
             linetype = 'dashed', size = 2, color = 'blue') +
  geom_label(aes(x = 25, y = 90, 
                 label = str_replace_all(toString(summary(moneyball_training['B_HR'])), ',', '\n')
                 )) +
  labs(title = 'Homeruns Histogram Plot', y = 'Count', x = 'Homeruns')


# Walks
ggplot(data = moneyball_training, aes(x = B_BB))  +
  geom_histogram( color = 'black', fill =  'gray') + 
  geom_vline(aes(xintercept = mean(B_BB)),
             linetype = 'dashed', size = 2, color = 'blue') +
  geom_label(aes(x = 380, y = 100, 
                 label = str_replace_all(toString(summary(moneyball_training['B_BB'])), ',', '\n')
                 )) +
  labs(title = 'Walks Histogram Plot', y = 'Count', x = 'Walks')


# Strike Out by Batters
ggplot(data = moneyball_training, aes(x = B_SO))  +
  geom_histogram( color = 'black', fill =  'gray') + 
  geom_vline(aes(xintercept = mean(B_SO)),
             linetype = 'dashed', size = 2, color = 'blue') +
  geom_label(aes(x = 380, y = 100, 
                 label = str_replace_all(toString(summary(moneyball_training['B_SO'])), ',', '\n')
                 )) +
  labs(title = 'Strike Out by Batters Histogram Plot', y = 'Count', x = 'Strike Out by Batters')


# Stolen Bases
ggplot(data = moneyball_training, aes(x = BR_SB))  +
  geom_histogram( color = 'black', fill =  'gray') + 
  geom_vline(aes(xintercept = mean(BR_SB)),
             linetype = 'dashed', size = 2, color = 'blue') +
  geom_label(aes(x = 200, y = 100, 
                 label = str_replace_all(toString(summary(moneyball_training['BR_SB'])), ',', '\n')
                 )) +
  labs(title = 'Stolen Bases Histogram Plot', y = 'Count', x = 'Stolen Bases')


# Hits Allowed
ggplot(data = moneyball_training, aes(x = P_H))  +
  geom_histogram( color = 'black', fill =  'gray') + 
  geom_vline(aes(xintercept = mean(P_H)),
             linetype = 'dashed', size = 2, color = 'blue') +
  geom_label(aes(x = 1250, y = 100, 
                 label = str_replace_all(toString(summary(moneyball_training['P_H'])), ',', '\n')
                 )) +
  labs(title = 'Hits Allowed Histogram Plot', y = 'Count', x = 'Hits Allowed')


# Homeruns Allowed
ggplot(data = moneyball_training, aes(x = P_HR))  +
  geom_histogram( color = 'black', fill =  'gray') + 
  geom_vline(aes(xintercept = mean(P_HR)),
             linetype = 'dashed', size = 2, color = 'blue') +
  geom_label(aes(x = 30, y = 90, 
                 label = str_replace_all(toString(summary(moneyball_training['P_HR'])), ',', '\n')
                 )) +
  labs(title = 'Homeruns Allowed Histogram Plot', y = 'Count', x = 'Homeruns Allowed')


# Walks Allowed
ggplot(data = moneyball_training, aes(x = P_BB))  +
  geom_histogram( color = 'black', fill =  'gray') + 
  geom_vline(aes(xintercept = mean(P_BB)),
             linetype = 'dashed', size = 2, color = 'blue') +
  geom_label(aes(x = 375, y = 100, 
                 label = str_replace_all(toString(summary(moneyball_training['P_BB'])), ',', '\n')
                 )) +
  labs(title = 'Walks Allowed Histogram Plot', y = 'Count', x = 'Walks Allowed')


# Strikeouts by Pitchers
ggplot(data = moneyball_training, aes(x = P_SO))  +
  geom_histogram( color = 'black', fill =  'gray') + 
  geom_vline(aes(xintercept = mean(P_SO)),
             linetype = 'dashed', size = 2, color = 'blue') +
  geom_label(aes(x = 425, y = 100, 
                 label = str_replace_all(toString(summary(moneyball_training['P_SO'])), ',', '\n')
                 )) +
  labs(title = 'Strikeouts by Pitchers Histogram Plot', y = 'Count', x = 'Strikeouts by Pitchers')


# Errors
ggplot(data = moneyball_training, aes(x = F_E))  +
  geom_histogram( color = 'black', fill =  'gray') + 
  geom_vline(aes(xintercept = mean(F_E)),
             linetype = 'dashed', size = 2, color = 'blue') +
  geom_label(aes(x = 225, y = 100, 
                 label = str_replace_all(toString(summary(moneyball_training['F_E'])), ',', '\n')
                 )) +
  labs(title = 'Errors Histogram Plot', y = 'Count', x = 'Errors')

# Double Plays
ggplot(data = moneyball_training, aes(x = F_DP))  +
  geom_histogram( color = 'black', fill =  'gray') + 
  geom_vline(aes(xintercept = mean(F_DP)),
             linetype = 'dashed', size = 2, color = 'blue') +
  geom_label(aes(x = 110, y = 100, 
                 label = str_replace_all(toString(summary(moneyball_training['F_DP'])), ',', '\n')
                 )) +
  labs(title = 'Double Plays Histogram Plot', y = 'Count', x = 'Double Plays')

```

To see what has the biggest impact on the results, we can evaluate the absolute value of the correlation of every feature.

```{r correlation}
# adapted from https://www.kaggle.com/reisel/how-to-handle-correlated-features

#start with field names
features <- training %>% select(-Wins) %>% names()

#initiate blank data frame
corr_coefs<- data.frame(feature = features, coef = rep(NA, length(features)))

#for every feature, calculate the correlation with the target, "Wins"
i <- 1
for (feature in features){
  df <- training[, c(feature, "Wins")] %>% na.omit() #omit NAs for each feature
  corr_coefs$coef[i] <- abs(cor(df[, feature], df$Wins))
  # print(feature)
  # print(i)
  # print(corr_coefs$coef[i])
  i <- i + 1
}

# sort by correlation coefficient
corr_coefs<- corr_coefs[order(corr_coefs$coef, decreasing = TRUE), ]

ggplot(corr_coefs, aes(x = factor(feature, levels = feature), y = coef)) + 
    geom_bar(stat = "identity") + 
    coord_flip() + 
    xlab("Feature") + 
    ylab("Correlation Coefficient")
```

## Model Testing

Then we can test some models

```{r}
lm_all <- lm(Wins ~ ., data = training) 
summary(lm_all)
```

Let's drop the feature with the most missing data and see if that helps.
```{r}
test <- function(droplist, data=training){
  df <- data %>% select(-all_of(droplist))
  lm <- lm(Wins ~ . , df) 

  print("R Squared")
  print(summary(lm)$adj.r.squared)
  return(summary(lm)$adj.r.squared)
}

missingALot <- c("HitByPitch_AtBat", "OutStealingBases", "DoublePlays")

test(missingALot)
  
```

The 5th round is slightly better than the 1st 4, but not by much.

Can we try removing the features with the lowest p-values?

```{r}
features2 <- summary(lm_all)$coefficients %>% data.frame %>% arrange(desc(Pr...t..))
features2
```

```{r}
test(c("StrikeOuts_AtBat", "StrikeOuts"))
```

## Removing Outliers

```{r eval=FALSE}
# removing outliers
out_ind <- c()
outliers <- c()

for (col in names(training)){
  
  out <- boxplot.stats(training[, col])$out
  outliers <- append(outliers, out)
  out_ind <- append(out_ind, which(training[, col] %in% c(out)))
  
}

# to see the outliers
# cbind(outliers, moneyball_training[out_ind,])

# removing the outliers
training_mod <- raining[-out_ind, ]
```

```{r}
lm2 <- lm(Wins ~ . -HomeRuns, data = training)
summary(lm2)

lm3 <- lm(Wins ~ . -HomeRuns -StrikeOuts_AtBat, data = training)
summary(lm3)

lm4 <- lm(Wins ~ . -HomeRuns -StrikeOuts_AtBat -Doubles, data = training)
summary(lm4)

# I've gone too far R-Squared has gone down
```

```{r}

ggplot(data = lm2, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_smooth(se = FALSE) +
  xlab("Fitted values") +
  ylab("Residuals")


ggplot(data = lm2, aes(x = .resid)) +
  geom_histogram() +
  xlab("Residuals")


ggplot(data = lm2) + 
  stat_qq(aes(sample = .stdresid)) +
  geom_abline()
```

## Model Selection

## Conclusions

## References

Sellmair, Reinhard. "How to handle correlated Features?" June 25, 2018. https://www.kaggle.com/reisel/how-to-handle-correlated-features

Xie, Yihui, J. J. Allaire, and Garrett Grolemund, *R Markdown: The Definitive Guide*, CRC PressDecember 14, 2020 https://bookdown.org/yihui/rmarkdown/r-code.html. 

https://rstatisticsblog.com/data-science-in-action/data-preprocessing/six-amazing-function-to-create-train-test-split-in-r/

